---
title: "Homework 3"
author: "Yuxi Wang"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("bayesplot","knitr","arm","ggplot2","rstanarm")
```


## Disclaimer

A few things to keep in mind :
1) Use set.seed() to make sure that the document produces the same random simulation as when you ran the code.
2) Use refresh=0 for any stan_glm() or stan-based model. lm() or non-stan models don't need this!
3) You can type outside of the r chunks and make new r chunks where it's convenient. Make sure it's clear which questions you're answering.
4) Even if you're not too confident, please try giving an answer to the text responses!
5) Please don't print data in the document unless the question asks. It's good for you to do it to look at the data, but not as good for someone trying to read the document later on.
6) Check your document before submitting! Please put your name where "name" is by the author!

## 4.1 Comparison of proportions
A randomized experiment is performed within a survey. 1000  people are contacted. Half the people contacted are promised a $5 incentive to participate, and  half are not promised an incentive. The result is a 50% response rate among the treated group  and 40% response rate among the control group. Give an estimate and standard error of the  average treatment effect. 

```{r}
n <- 1000
n1 <- n/2
n2 <- n-n/2
estimate1 <- 0.5
estimate2 <- 0.4
estimate <- (n1*0.5+n2*0.4)/n
print(paste("The setimated number of the  average treatment effect ", estimate))
se <- sqrt((estimate*(1-estimate))/n)
print(paste("The standard error of the  average treatment effect is:", se))
```

## 4.2 Choosing sample size
You are designing a survey to estimate the gender gap: the difference in support for a candidate among men and women. Assuming the respondents are a simple random sample of the voting population, how many people do you need to poll so that the standard error is less than 5 percentage points? 


```{r}
n_male1=1
n_male2=1
n_female1=1
n_female2 =1
repeat{

  n_male <- n_male1+n_male2
  n_female <- n_female1+n_female2 
  n <- n_male + n_female
  y_male <- rep(c(0,1),c(n_male1,n_male2))
  se_male <- sd(y_male)/sqrt(n_male)
  y_female <- rep(c(0,1),c(n_female1,n_female2))
  se_female <- sd(y_female)/sqrt(n_female)
  if(sqrt(se_male^2+se_female^2)<=0.05) break
  else
    n_male1= n_male1+1
    n_male2=n_male2+1
    n_female1=n_female1+1
    n_female2 =n_female2+1
}
print(paste("The size of N is at least ", n))

```

## 4.4 Designing an experiment
You want to gather data to determine which of two students is a  better basketball shooter. You plan to have each student take N shots and then compare their  shooting percentages. Roughly how large does N have to be for you to have a good chance of  distinguishing a 30% shooter from a 40% shooter? 

```{r}
estimate_a <- 0.3
estimate_b <- 0.4
n <- 1
repeat{
  se_a <- sqrt(estimate_a*(1-estimate_a)/n)
  se_b <- sqrt(estimate_b*(1-estimate_b)/n)
  if
  (sqrt(se_a^2+se_b^2)<=0.05) break
  else
    n <- n+1
}
print(paste("The size of N is at least ", n))

```


## 4.6 Hypothesis testing
The following are the proportions of girl births in Vienna for each month in  Girl births 1908 and 1909 (out of an average of 3900 births per month):

```{r}
birthdata <- c(.4777,.4875,.4859,.4754,.4874,.4864,.4813,.4787,.4895,.4797,.4876,.4859,
               .4857,.4907,.5010,.4903,.4860,.4911,.4871,.4725,.4822,.4870,.4823,.4973)
```

The data are in the folder Girls. These proportions were used by von Mises (1957) to support  a claim that that the sex ratios were less variable than would be expected under the binomial  distribution. We think von Mises was mistaken in that he did not account for the possibility that  this discrepancy could arise just by chance.  

### (a) Compute the standard deviation of these proportions and compare to the standard deviation  that would be expected if the sexes of babies were independently decided with a constant  probability over the 24-month period.  

```{r}
n <- 3900
sd <- sd(birthdata)
print(paste("The standard deviation of these proportions is:", sd))
mean <- mean(birthdata)
sd_exp <- sqrt(mean*(1-mean)/n)
print(paste("The expected standard deviation is:", sd_exp))
```

### (b) The observed standard deviation of the 24 proportions will not be identical to its theoretical  expectation. In this case, is this difference small enough to be explained by random variation?  Under the randomness model, the actual variance should have a distribution with expected  value equal to the theoretical variance, and proportional to a chi-square random variable with 23  degrees of freedom; see page 53. 

```{r}
alpha <- 0.05
upper <- qchisq(alpha/2., (24-1))
sd_upper <- sqrt(23*(sd^2)/upper)
lower <- qchisq(1 - (alpha/2.), (24-1))
sd_lower <- sqrt(23*(sd^2)/lower)
print(paste(sd_lower,"< sigma <", sd_upper))
```
## After understanding our output, we can find that the observed standard deviation of the 24 proportions is not identical to its theoretical expectation. While the difference is small enough to be explained by random variation.


## 5.5 Distribution of averages and differences
The heights of men in the United States are approximately  normally distributed with mean 69.1 inches and standard deviation 2.9 inches. The heights of  women are approximately normally distributed with mean 63.7 inches and standard deviation  2.7 inches. Let x be the average height of 100 randomly sampled men, and y be the average  height of 100 randomly sampled women. In R, create 1000 simulations of x - y and plot their  histogram. Using the simulations, compute the mean and standard deviation of the distribution  of x - y and compare to their exact values. 

```{r}
set.seed(1213)
n_sims <- 1000
mean <- rep(NA, n_sims)

x <- replicate(n_sims,{
  rnorm(100,mean=69.1,sd=2.9)
})

y <- replicate(n_sims,{
  rnorm(100,mean=63.7,sd=2.7)
})
mean <- mean(x-y)
sd <- sd(x-y)

print(paste("The mean of x-y is:", mean))
print(paste("The standard deviation of x-y is:", sd))
hist(x-y,main="simulations of x - y")
## We compare the estimated number with exact values:
## The mean of x-y is about: 5.39. While, the exact value is 69.1-63.7= 5.4
## The standard deviation of x-y is about: 3.98. While, the exact value is sqrt(2.9^2+2.7^2)= 3.96
```

## 5.6 Propagation of uncertainty: 
We use a highly idealized setting to illustrate the use of simulations  in combining uncertainties. Suppose a company changes its technology for widget production,  and a study estimates the cost savings at 5 dollars per unit, but with a standard error of 4 dollars. Furthermore,  a forecast estimates the size of the market (that is, the number of widgets that will be sold)  at 40 000, with a standard error of 10 000. Assuming these two sources of uncertainty are  independent, use simulation to estimate the total amount of money saved by the new product  (that is, savings per unit, multiplied by size of the market). 

```{r}
# According to the question，we know that:
set.seed(1213)
mean_save <- 5
se_save <- 4
size_market <- 40000
se_market <- 10000
n_sims <- 1000
total<- rep(NA, n_sims)
for (i in 1:n_sims) {
    market <- rnorm(n=1, mean=size_market, sd=se_market)
    savings <- rnorm(n=1, mean=mean_save, sd=se_save)
    total[i] <- market * savings
}
summary(total)
hist(total,main="the total amount of money saved by the new product")
```

## 5.8 Coverage of confidence intervals: 
On page 15 there is a discussion of an experimental study of  an education-related intervention in Jamaica, in which the point estimate of the treatment effect,  on the log scale, was 0.35 with a standard error of 0.17. Suppose the true effect is 0.10—this  seems more realistic than the point estimate of 0.35—so that the treatment on average would  increase earnings by 0.10 on the log scale. Use simulation to study the statistical properties of  this experiment, assuming the standard error is 0.17.  

```{r}
```

### (a) Simulate 1000 independent replications of the experiment assuming that the point estimate is  normally distributed with mean 0.10 and standard deviation 0.17.  

```{r}
set.seed(1213)
mean <- 0.10
sd <- 0.17
n_sims <- 1000
n=127  #since we have 127 children in page 15
effect <- replicate(n_sims,{
  rnorm(n,0.1,0.17)
})
print(paste("1000 simulations completed"))
```

### (b) For each replication, compute the 95% confidence interval. Check how many of these intervals  include the true parameter value.  

```{r}
n_sims <- 1000
for(i in 1:n_sims){
   effect[,i] <- sort(effect[,i])
}
lower <- 0
upper <- 0
for (i in 1:n_sims){
  lower[i] <- mean(effect[,i])-1.96*sd(effect[,i])/sqrt(127)
  upper[i] <- mean(effect[,i])+1.96*sd(effect[,i])/sqrt(127)
}
 
include <- 0
for(i in 1:n_sims){
  if(lower[i]<=0.1 && upper[i]>=0.1){
    include <- include+1
  }
}
print(paste("there are",include,"intervals include the true parameter value"))
```

### (c) Compute the average and standard deviation of the 1000 point estimates; these represent the  mean and standard deviation of the sampling distribution of the estimated treatment effect. 

```{r}
set.seed(1213)
mean <- 0.10
sd <- 0.17
n_sims <- 1000
n=127  #since we have 127 children in page 15
effect <- replicate(n_sims,{
  rnorm(n,0.1,0.17)
})
average <- mean(effect)
standard_deviation <- sd(effect)
print(paste("the average of the 1000 point estimates is",average))
print(paste("the standard deviation of the 1000 point estimates",standard_deviation))
```

## 5.9 Coverage of confidence intervals after selection on statistical significance: 
Take your 1000  simulations from Exercise 5.8, and select just the ones where the estimate is statistically  significantly different from zero. Compute the average and standard deviation of the selected point estimates. Compare these to the result from Exercise 5.8. 

```{r}
set.seed(1213)
mean <- 0.10
sd <- 0.17
n_sims <- 1000
n=127  #since we have 127 children in page 15
effect <- replicate(n_sims,{
  rnorm(n,0.1,0.17)
})
#define 0.05 as a selection on statistical significance
selected <- 0
for(i in 1:n_sims){
  if(abs(effect[i])>=0.05){
    selected[i] <- effect[i]
  }
}
print(paste("the average of the selected point is",mean(selected, na.rm=T)))
print(paste("the standard deviation of the selected point is",sd(selected, na.rm=T)))

## According to the result, we can find that the average and standard deviation of selected data which have statistical significance is higher than the result of the original data.
```

## 9.8 Simulation for decision analysis: 
An experiment is performed to measure the efficacy of a television advertising program. The result is an estimate that each minute spent on a national advertising program will increase sales by 500,000 dollars, and this estimate has a standard error of  200000 dollars. Assume the uncertainty in the treatment effect can be approximated by a normal  distribution. Suppose ads cost 300000 dollars per minute. What is the expected net gain for purchasing  20 minutes of ads? What is the probability that the net gain is negative? 

```{r}
# According to the question, we know that
set.seed(1213)
mean_income <- 500000
sd <- income <- 200000
cost <- 300000
# Stimulate the data for 100000 times
income <- replicate(100000,{
  rnorm(1,500000,200000)
})
average <- mean(income)
expected_net_gain <- 20*(average-cost)
print(paste("the expected net gain for purchasing  20 minutes of ads are",expected_net_gain))
negative <- 0
for(i in 1:100000){
  if(income[i]<=cost){
    negative <- negative+1
  }
}
ratio_negative <- negative/100000
print(paste("the probability that the net gain is negative is",ratio_negative))
```

## 10.3 Checking statistical significance: 
In this exercise and the next, you will simulate two variables that are statistically independent of each other to see what happens when we run a regression to predict one from the other. Generate 1000 data points from a normal distribution with mean 0  and standard deviation 1 by typing var1 <- rnorm(1000,0,1) in R. Generate another variable  in the same way (call it var2). Run a regression of one variable on the other. Is the slope coefficient “statistically significant”? We do not recommend summarizing regressions in this way, but it can be useful to understand how this works, given that others will do so. 

```{r}

var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
regression <- lm(var2~var1)
summary(regression)
opar <- par(mfrow=c(2,2))
plot(regression)
par(opar)
```
## After understanding the result of the code, we can easily find that the p-value of the slope is 0.7481, which means that the coefficient of slope is not statistically significant.


## 10.4 Simulation study of statistical significance: 
Continuing the previous exercise, run a simulation  repeating this process 100 times. This can be done using a loop. From each simulation, save the  z-score (the estimated coefficient of var1 divided by its standard error). If the absolute value of  the z-score exceeds 2, the estimate is “statistically significant.”  To perform this computation, we start by creating an empty vector of z-scores filled with missing values (NAs). Another approach is to start with z_scores <- numeric(length=100), which  would set up a vector of zeroes. In general, however, we prefer to initialize with NAs, because  then when there is a bug in the code, it sometimes shows up as NAs in the final results, alerting  us to the problem. 

How many of these 100 z-scores exceed 2 in absolute value, thus achieving the conventional level of statistical significance? 

Here is code to perform the simulation:

This chunk will have eval=FALSE. If you want it to run, please copy it to a new chunk, or remove eval=FALSE!

```{r}
set.seed(1213)
z_scores <- rep(NA,100)
for(k in 1:100) {
  var1 <- rnorm(1000,0,1)
  var2 <- rnorm(1000,0,1)
  fake <- data.frame(var1,var2)
  fit <- stan_glm(var2 ~ var1,data=fake,refresh=0)
  z_scores[k] <- coef(fit)[2] / se(fit)[2]
}
number <- 0
for(k in 1:100){
  if(abs(z_scores[k])>=2){
    number <- number+1
  }
}
print(paste("the number of these 100 z-scores exceed 2 in absolute value is:",number))
```

## 11.3 Coverage of confidence intervals: 
Consider the following procedure:  

- Set n = 100 and draw n continuous values xi uniformly distributed between 0 and 10. Then  simulate data from the model yi = a + bxi + errori, for i = 1,..., n, with a = 2, b = 3, and  independent errors from a normal distribution.  

- Regress y on x. Look at the median and mad sd of b. Check to see if the interval formed by  the median ± 2 mad sd includes the true value, b = 3.  

- Repeat the above two steps 1000 times.  
```{r}

```


### (a) True or false: the interval should contain the true value approximately 950 times. Explain  your answer.  
```{r}
set.seed(1213)
B <- 0
median <- rep(NA,1000)
for(k in 1:1000) {
  n <- 100
  a <- 2
  b <- 3
  x <- runif(n,min=0,max=10)
  err <- rnorm(n,0,1)
  y <- a + b*x + err
  fake <- data.frame(x,y)
  fit <- lm(y ~ x)
  B[k] <- coef(fit)[2]
}
median(B)
mad(B)
number <- 0
if(median(B)-2*mad(B)<b &&median(B)+2*mad(B)>b){
  number <- number+1
  }
number
```

## True. The result that I stimulate is 1000-1=999. Which 999>950.

### (b) Same as above, except the error distribution is bimodal, not normal. True or false: the  interval should contain the true value approximately 950 times. Explain your answer. 
```{r}
set.seed(1213)
B <- 0
median <- rep(NA,1000)
for(k in 1:1000) {
  n <- 100
  a <- 2
  b <- 3
  x <- runif(n,min=0,max=10)
  err <- rbinom(n, 1, 0.5)
  y <- a + b*x + err
  fake <- data.frame(x,y)
  fit <- lm(y ~ x)
  B[k] <- coef(fit)[2]
}
median(B)
mad(B)
number <- 0
if(median(B)-2*mad(B)<b &&median(B)+2*mad(B)>b){
  number <- number+1
  }
number
```
## True. The result that I stimulate is 1000-1=999. Which 999>950.

## Optional:
## 11.6 Fitting a wrong model: 
Suppose you have 100 data points that arose from the following model:  y = 3 + 0.1 x1 + 0.5 x2 + error, with independent errors drawn from a t distribution with mean  0, scale 5, and 4 degrees of freedom. We shall explore the implications of fitting a standard  linear regression to these data.  

###(a) Simulate data from this model. For simplicity, suppose the values of x1 are simply the  integers from 1 to 100, and that the values of x2 are random and equally likely to be 0 or  1. In R, you can define x_1 <- 1:100, simulate x_2 using rbinom, then create the linear  predictor, and finally simulate the random errors in y using the rt function. Fit a linear  regression (with normal errors) to these data and see if the 68% confidence intervals for the  regression coefficients (for each, the estimates ±1 standard error) cover the true values.  

```{r}
set.seed(1213)
x1 <- c(1:100)
x2 <-  rbinom(100, 1, 0.5)
err <- rt(100,4)
a <- 0.1
b <- 0.5
c <- 3
y <- c+1*x1+b*x2+err
fake <- data.frame(x,y)
fit <- stan_glm(y ~ x,data=fake,refresh=0)
summary(fit)
```

### (b) Put the above step in a loop and repeat 1000 times. Calculate the confidence coverage for  the 68% intervals for each of the three coefficients in the model. 

```{r}

```

## 11.9 Leave-one-out cross validation: 
Use LOO to compare different models fit to the beauty and  teaching evaluations example from Exercise 10.6:  

```{r}

```

###(a) Discuss the LOO results for the different models and what this implies, or should imply, for  model choice in this example.  

### (b) Compare predictive errors pointwise. Are there some data points that have high predictive  errors for all the fitted models? 

## 11.10 K-fold cross validation: 
Repeat part (a) of the previous example, but using 5-fold cross  validation:  

###(a) Randomly partition the data into five parts using the sample function in R.

```{r}

```

### (b) For each part, re-fitting the model excluding that part, then use each fitted model to predict  the outcomes for the left-out part, and compute the sum of squared errors for the prediction.  

```{r}

```

### (c) For each model, add up the sum of squared errors for the five steps in (b). Compare the  different models based on this fit. 

```{r}

```

### (d) Not in the textbook, but if you're curious, compare your results to kfold() or cv.glm()! 
 
```{r}

```
